{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "3eXpmfhEiEP_",
        "VMdRHRGHj1Vs",
        "0_JL2b6wj5jo"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhouldridge/repertoire/blob/main/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "degGs-PaQyKa"
      },
      "source": [
        "#Linear Regression: Project 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtjBkiSxuT9o"
      },
      "source": [
        "By: Benjamin Houldirdge\n",
        "\n",
        "July 30th 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eXpmfhEiEP_"
      },
      "source": [
        "##Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC7-c35xii5b"
      },
      "source": [
        "This is an unidimensional regression problem, which predicts the sale price of a property based on available information. The ideal outcome is to provide information about what a property's true market value is. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b2Vt10xiIQ8"
      },
      "source": [
        "##Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_w5G5DzjFHA"
      },
      "source": [
        "###Import nessasary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i1bzadMgNLQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.model_selection as model_selection\n",
        "from sklearn import preprocessing\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uu_WoemjrFw"
      },
      "source": [
        "###Mount to Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjocl4oxjjMj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMdRHRGHj1Vs"
      },
      "source": [
        "###Import Data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGpf5hlxjwrI"
      },
      "source": [
        "# data_path = '/content/drive/My Drive/Exercises - Benjamin/Project 2/Copy of Housing Data.csv'\n",
        "data_path = '/content/drive/My Drive/Data Science Student Material/Project 2/Data/Housing Data.csv'\n",
        "data_original = pd.read_csv(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_JL2b6wj5jo"
      },
      "source": [
        "###Reserve copy of original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdGBBrUnFClt"
      },
      "source": [
        "data = data_original.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4toGFX0IiNRL"
      },
      "source": [
        "##Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bgj-nDakDxO"
      },
      "source": [
        "###Inspect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL8FeBZzlMxV"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gmm1NyR8yMC"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaI93yuPkLL8"
      },
      "source": [
        "Check Columns and first few rows of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFm8ck1dkOWp"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGthAonTkaqf"
      },
      "source": [
        "###Drop Unessasary Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_dIQ8ZIR5aR"
      },
      "source": [
        "data = data.drop(['PID'], axis=1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0qwAGgLkcYy"
      },
      "source": [
        "###Fill Nan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh7LhMPzG-7k"
      },
      "source": [
        "data['Lot Frontage'] = data['Lot Frontage'].fillna(0)\n",
        "data['Alley'] = data['Alley'].fillna('None')\n",
        "data['Mas Vnr Type'] = data['Mas Vnr Type'].fillna('None')\n",
        "data['Mas Vnr Area'] = data['Mas Vnr Area'].fillna(0)\n",
        "data['Fireplace Qu'] = data['Fireplace Qu'].fillna('None')\n",
        "data['Pool QC'] = data['Pool QC'].fillna('None')\n",
        "data['Fence'] = data['Fence'].fillna('No Fence')\n",
        "data['Misc Feature'] = data['Misc Feature'].fillna('None')\n",
        "data['Total Bsmt SF'] = data['Total Bsmt SF'].fillna(0)\n",
        "data['Bsmt Full Bath'] = data['Bsmt Full Bath'].fillna(0)\n",
        "data['Bsmt Half Bath'] = data['Bsmt Half Bath'].fillna(0)\n",
        "data['Bsmt Unf SF'] = data['Bsmt Unf SF'].fillna(0)\n",
        "data['Bsmt Qual']= data['Bsmt Qual'].fillna('No Basement')\n",
        "data['Bsmt Cond'] = data['Bsmt Cond'].fillna('No Basement')\n",
        "data['Bsmt Exposure'] = data['Bsmt Exposure'].fillna('No Basement')\n",
        "data['BsmtFin Type 1'] = data['BsmtFin Type 1'].fillna('No Basement')\n",
        "data['BsmtFin SF 1'] = data['BsmtFin SF 1'].fillna('No Basement')\n",
        "data['BsmtFin Type 2'] = data['BsmtFin Type 2'].fillna('No Basement')\n",
        "data['BsmtFin SF 2'] = data['BsmtFin SF 2'].fillna('No Basement')\n",
        "data['Garage Type'] = data['Garage Type'].fillna('No Garage')\n",
        "data['Garage Cond'] = data['Garage Cond'].fillna('No Garage')\n",
        "data['Garage Qual'] = data['Garage Qual'].fillna('No Garage')\n",
        "data['Garage Area'] = data['Garage Area'].fillna(0)\n",
        "data['Garage Cars'] = data['Garage Cars'].fillna(0)\n",
        "data['Garage Finish'] = data['Garage Finish'].fillna('No Garage')\n",
        "data['Garage Type'] = data['Garage Type'].fillna('No Garage')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIwdQFdGXCCl"
      },
      "source": [
        "Change Nan values in 'Garage Yr Blt'. Nan values with no garage will be one-hoted to a new column titled 'No Garage'. Nan values with a garage will be replaced with the year the home was built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lgKcWAf3mn-"
      },
      "source": [
        "data.insert(59, 'No Garage', 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZp8KCb8XBno"
      },
      "source": [
        "missing_values = pd.isna(data)\n",
        "for idx, series in data.iterrows():\n",
        "  if missing_values.at[idx, 'Garage Yr Blt'] == True:\n",
        "    if data.at[idx, 'Garage Area'] == 0:\n",
        "      data.at[idx, 'No Garage'] = 1\n",
        "      data.at[idx, 'Garage Yr Blt'] = 0\n",
        "    else:\n",
        "      data.at[idx, 'Garage Yr Blt'] = data.at[idx, 'Year Built']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qsOPtOOkn9G"
      },
      "source": [
        "###Check for Incompatable Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk6n8o10PGqM"
      },
      "source": [
        "def incompatable_check(column1, attribute1, column2, attribute2, dataframe = data):\n",
        "  \"\"\" Return index of all rows for which attribute1 and attribute2 are not compatable.\"\"\"\n",
        "  \n",
        "  incompatable = []\n",
        "  for idx, series in dataframe.iterrows():\n",
        "    if series[column1] == attribute1 and series[column2] == attribute2:\n",
        "      continue\n",
        "    elif series[column1] != attribute1 and series[column2] != attribute2:\n",
        "      continue\n",
        "    else:\n",
        "      incompatable.append(idx)\n",
        "  return incompatable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPKVE4cL-ZwF"
      },
      "source": [
        "The one incompatability that I found was in row 329. Garage type showes Detchd and the Area is 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GwfNw4WvaEF"
      },
      "source": [
        "incompatable1 = incompatable_check('Garage Area', 0, 'Garage Type', 'No Garage')\n",
        "print(incompatable1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtuEOmT1KWg0"
      },
      "source": [
        "Drop line "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSEo2Fb3-bJX"
      },
      "source": [
        "data = data.drop(329, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iq7jk7AS2pI"
      },
      "source": [
        "Showing lines 162, 329, 2005 which where droped in class. \n",
        "\n",
        "Line 329 is droped for above reason. \n",
        "\n",
        "Line 162 dosn't have any inconsistacny I can find.\n",
        "\n",
        "Line 2005 looks like \"BsmtFin Type 2\" is Unf with \"BsmtFin SF 2\" 0 and \"Bsmt Unf SF\" 226.0. This looks to be inconsitant but the accompianing documentation seems internaly inconsitant. The documentation discribes BsmtFin Type 1 and 2 as \"rating of basment finished area.\" and yet has unfinished as an option of type. If we threw out every entry with and unfinished type that has 0 square feet but shows a positive number for Bsmt Unf SF then we would have to throw out 768 rows. I'm going to assume that during data colection BsmtFin SF 1 and 2 where left at 0 if the type was unfinished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFzjd6I38Sp9"
      },
      "source": [
        "data_original.filter(items=[162,329,2005], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CJTBlRY_Njr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVe5ps8jMau3"
      },
      "source": [
        "check1 = data[data['BsmtFin Type 2']=='Unf']\n",
        "check2 = check1[check1['Bsmt Unf SF']!=0]\n",
        "check3 = check2[check2['BsmtFin Type 1']=='Unf']\n",
        "len(check3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd87tZwJI2xK"
      },
      "source": [
        "Abnormal and partial sales are producing outlires in SalePrice. Keep only the rows whith sale condition is normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUqInapnJOQy"
      },
      "source": [
        "data = data[data['Sale Condition'] == 'Normal']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqPpvc7LWWTb"
      },
      "source": [
        "###Reindex Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4tttzWWWeFE"
      },
      "source": [
        "data = data.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Giqqe5-Wtt3"
      },
      "source": [
        "Check for any abnormalities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd3kk8Exzsg-"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Pnvd7NVZsZ"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFe3P0spBLKH"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEwlromKiSU7"
      },
      "source": [
        "##Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h2kYA8r8MdA"
      },
      "source": [
        "###Get Correlations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkPsCHMpVDJZ"
      },
      "source": [
        "def build_correlation_list(data_frame=data):\n",
        "  \"\"\"Return a list of highest corilated values from the data dataframe.\"\"\"\n",
        "\n",
        "  data_correlation  = data_frame.corr()['SalePrice']\n",
        "  correlation_list = data_correlation.abs().sort_values(ascending=False)\n",
        "  correlation_list = correlation_list.drop('SalePrice', axis=0)\n",
        "  return correlation_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqKNGG3NIWRn"
      },
      "source": [
        "correlation_list = build_correlation_list()\n",
        "print(correlation_list)\n",
        "print(correlation_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my79LB_2GoYf"
      },
      "source": [
        "### Error Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aj9DaZCH6Yf"
      },
      "source": [
        "def numeric_sets(data_frame=data):\n",
        "  \"\"\"Produce a dataframe of saleprices and a numeric values.\"\"\"\n",
        "  \n",
        "  features_all = data_frame.drop('SalePrice', axis=1)\n",
        "  saleprice = data_frame['SalePrice']\n",
        "  features_numeric = features_all.select_dtypes(include=['int64', 'float64'])\n",
        "  return saleprice, features_numeric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62NtW3zNDYbm"
      },
      "source": [
        "def mean_of_rsquared(features, itterations=1000):\n",
        "  \"\"\"Retun a dictionary with the mean of the r_squared and rms_error of a model ran itterations times\"\"\"\n",
        "\n",
        "  r_squared_values = []\n",
        "  rms_predicted_error = []\n",
        "  for idx in range(itterations):\n",
        "    train_variables, test_variables, train_saleprice, test_saleprice = model_selection.train_test_split(features, saleprice, test_size=.2)\n",
        "    model = sm.OLS(train_saleprice, train_variables).fit()\n",
        "    prediction = model.predict(test_variables)\n",
        "    rmspe = np.sqrt(np.mean(np.square((test_saleprice - prediction)/test_saleprice)))*100\n",
        "\n",
        "    rms_predicted_error.append(rmspe)\n",
        "    r_squared_values.append(model.rsquared)\n",
        "\n",
        "  return np.mean(r_squared_values), np.mean(rms_predicted_error) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bURW8hqDIs4k"
      },
      "source": [
        "def itterate_numeric(num_features):\n",
        "  \"\"\"Return an array with the precentage error for the model as features are added.\"\"\"\n",
        "\n",
        "  r_squared_values = []\n",
        "  rms_error_values = []\n",
        "  for idx in range(0,num_features):\n",
        "    features_reduced = pd.DataFrame(features_numeric[correlation_list.index[:idx+1]].copy())\n",
        "    features_reduced['Ones'] = 1\n",
        "\n",
        "    r_squared, rms_error = mean_of_rsquared(features_reduced)\n",
        "    r_squared_values.append(r_squared)\n",
        "    rms_error_values.append(rms_error)\n",
        "    print( str(idx+1) + ' feature compleet')\n",
        "  return {'r_squared':r_squared_values, 'rms_error':rms_error_values}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnAvRb_TIh-D"
      },
      "source": [
        "saleprice, features_numeric = numeric_sets()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ3zfzffHzQ5"
      },
      "source": [
        "###Eliminate Unessasary Numerical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4ypYqdau5UY"
      },
      "source": [
        "Produce cross validation errors for numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js3COAVzTFt0"
      },
      "source": [
        "numeric_features_error = itterate_numeric(35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjXPXfTcYr6u"
      },
      "source": [
        "print(numeric_features_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M05jLOxS4jY"
      },
      "source": [
        "Graph change in R-Squared and RMS values as features are added to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii480XI-TW76"
      },
      "source": [
        "sns.set()\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(numeric_features_error['r_squared'])\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('R-Squared')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIh8rV_XZMmN"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(numeric_features_error['rms_error'])\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Root Mean Squared Percentage Error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AOvKX9vcSXa"
      },
      "source": [
        "print(numeric_features_error['rms_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zp75gFe_Z3y"
      },
      "source": [
        "Find freatures that increase the root mean square error when added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_fPfBk0_RPA"
      },
      "source": [
        "def find_variables_that_increese_error():\n",
        "  idx_of_negitive_variables = []\n",
        "  for idx, value in enumerate(numeric_features_error['rms_error']):\n",
        "    if value - numeric_features_error['rms_error'][idx-1] > .1:\n",
        "      idx_of_negitive_variables.append(idx)\n",
        "  idx_of_negitive_variables.remove(0)\n",
        "  print(idx_of_negitive_variables)\n",
        "\n",
        "  labels = []\n",
        "  for idx in idx_of_negitive_variables:\n",
        "    labels.append(correlation_list.index[idx])\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvN2QKkvQEE6"
      },
      "source": [
        "labels = find_variables_that_increese_error()\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9s4ZisWDY9_"
      },
      "source": [
        "Drop Features that increse error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYx7LxoLFX6W"
      },
      "source": [
        "data = data.drop(columns=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-p5mUfXMgyD"
      },
      "source": [
        "Drop unuseful features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6ciMommMusp"
      },
      "source": [
        "data = data.drop(columns=correlation_list.index[-6:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44FiaP1U_6dh"
      },
      "source": [
        "Recalculate corrilation list and graph rms error precentage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-njtSaO08cs"
      },
      "source": [
        "correlation_list = build_correlation_list(data)\n",
        "print(correlation_list)\n",
        "print(correlation_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYFG4rmd1Dby"
      },
      "source": [
        "saleprice, features_numeric = numeric_sets()\n",
        "numeric_features_error = itterate_numeric(len(correlation_list))\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(numeric_features_error['rms_error'])\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Root Mean Squared Percentage Error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmirvyBt_gb1"
      },
      "source": [
        "print(numeric_features_error['rms_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ3O9hE6EZwS"
      },
      "source": [
        "###Seperate Numeric and Object Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtj7fkMfEqzp"
      },
      "source": [
        "data_numeric = data.select_dtypes(exclude='object').copy()\n",
        "data_objects = data.select_dtypes(include='object').copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM5W15I5Mfx3"
      },
      "source": [
        "###Scale Numeric Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBKYwzYXBMg5"
      },
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data_numeric)\n",
        "scaled_data = pd.DataFrame(scaled_data, columns= data_numeric.columns)\n",
        "scaled_data['SalePrice'] = data_numeric['SalePrice'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFIs1ymzyxHM"
      },
      "source": [
        "###Scaled and original data sets produce the same results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqASPU7Gzv-p"
      },
      "source": [
        "Train and test original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmkyCCaozGGg"
      },
      "source": [
        "data_numeric_variables = data_numeric.drop('SalePrice', axis=1)\n",
        "data_numeric_variables['Ones'] = 1\n",
        "data_numeric_saleprice = data_numeric['SalePrice']\n",
        "model = sm.OLS(data_numeric_saleprice, data_numeric_variables).fit()\n",
        "prediction1 = model.predict(data_numeric_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfKJVmPE2eD9"
      },
      "source": [
        "Train and test scaled data[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R55ylamp3NbB"
      },
      "source": [
        "scaled_data_variables = scaled_data.drop('SalePrice', axis=1)\n",
        "scaled_data_variables['Ones'] = 1\n",
        "scaled_data_saleprice = data_numeric['SalePrice']\n",
        "model = sm.OLS(scaled_data_saleprice, scaled_data_variables).fit()\n",
        "prediction2 = model.predict(scaled_data_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GULdY1rv3okY"
      },
      "source": [
        "Compare predictions of original and scaled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaPrRV2e3y0o"
      },
      "source": [
        "print((prediction1 - prediction2).max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8H3Sp-c4QlO"
      },
      "source": [
        "The largest discrepency is on the order of e-8 so we can safely assume that the scaled results are equivilant for our uses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7OHHNo-CSpd"
      },
      "source": [
        "data_numeric_scaled = scaled_data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZPmXkaoaRwj"
      },
      "source": [
        "###One Hot catigorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e0LIHkKr9Z6"
      },
      "source": [
        "Find out which values should be one hotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hunwk00M4vU5"
      },
      "source": [
        "def rmspe(train, outcomes, itterations=50):\n",
        "  \"\"\"calculate the rmspe itteration times and return the mean.\"\"\"\n",
        "\n",
        "  error_vector = []\n",
        "  for idx in range(itterations):\n",
        "    x_train, x_test, y_train, y_test = model_selection.train_test_split(train, outcomes, test_size=.2)\n",
        "    model = sm.OLS(y_train, x_train).fit()\n",
        "    predict = model.predict(x_test)\n",
        "    error_vector.append(np.sqrt(np.mean(np.square((y_test - predict)/y_test)))*100)\n",
        "  return np.mean(error_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39_isXSSMqai"
      },
      "source": [
        "def one_hot_efficacy(numeric=data_numeric_scaled, objects=data_objects):\n",
        "  \"\"\"One-hot each variable and test it's change on preformence.\"\"\"\n",
        "\n",
        "  #set up numeric variables, and calculate error with no one_hot featurs.\n",
        "  outcomes = numeric['SalePrice']\n",
        "  numeric = numeric.drop(['SalePrice'], axis=1)\n",
        "  numeric['Ones'] = 1\n",
        "  base_error = rmspe(numeric, outcomes)\n",
        "  errors = []\n",
        "  \n",
        "\n",
        "  for column in objects.columns:\n",
        "    feature = pd.get_dummies(objects[column])\n",
        "    train_data = pd.concat([numeric, feature], axis=1)\n",
        "    errors.append(rmspe(train_data, outcomes))\n",
        "  \n",
        "  errors_series = pd.Series(data=errors, index=objects.columns)\n",
        "  change_in_error = errors_series.subtract(base_error)\n",
        "  change_in_error_sorted = change_in_error.sort_values()\n",
        "  return change_in_error_sorted\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZux9uR3sion"
      },
      "source": [
        "List the object values by change in error when cross validated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV559UM9Ppae"
      },
      "source": [
        "objects_ranked = one_hot_efficacy()\n",
        "print(objects_ranked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaoPy0GiwOOl"
      },
      "source": [
        "Function that returns the error as one-hot features are added."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNIwilUXwN2f"
      },
      "source": [
        "def one_hot_efficacy(numeric=data_numeric_scaled, objects=data_objects, ranked_list=objects_ranked):\n",
        "  \"\"\"One-hot variables one by one and test the affect on preformence.\"\"\"\n",
        "\n",
        "  #set up numeric variables.\n",
        "  outcomes = numeric['SalePrice']\n",
        "  numeric = numeric.drop(['SalePrice'], axis=1)\n",
        "  numeric['Ones'] = 1\n",
        "  train_data = numeric.copy()\n",
        "  errors = []\n",
        "\n",
        "  for column in ranked_list.index:\n",
        "    feature = pd.get_dummies(objects[column])\n",
        "    train_data = pd.concat([train_data, feature], axis=1)\n",
        "    errors.append(rmspe(train_data, outcomes))\n",
        "\n",
        "  errors_series = pd.Series(data=errors, index=ranked_list.index)\n",
        "  return errors_series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTD1Qqop599E"
      },
      "source": [
        "one_hot_error = one_hot_efficacy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2He0rSi7jEn"
      },
      "source": [
        "Graph the change in error as features are added."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZLqhHi97rbS"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(range(45), one_hot_error)\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Root Mean Squared Precentage Error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0_usfxYEZbm"
      },
      "source": [
        "From the graph it looks like the low point in error is around 15. Print out the actual values to make sure. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHEkIWwwBEMH"
      },
      "source": [
        "one_hot_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3G08TJKBgA-"
      },
      "source": [
        "Select only the first 15 features for one hot coding and produce a dataframe with all the"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEWa0TWkCxaz"
      },
      "source": [
        "def one_hot_final(numeric=data_numeric_scaled, objects=data_objects, ranked_list=objects_ranked):\n",
        "  \"\"\"One-hot first 15 variables one by one and test the affect on preformence.\"\"\"\n",
        "\n",
        "  #set up numeric variables.\n",
        "  outcomes = numeric['SalePrice']\n",
        "  numeric['Ones'] = 1\n",
        "  train_data = numeric.copy()\n",
        "\n",
        "  for column in ranked_list.index[:15]:\n",
        "    feature = pd.get_dummies(objects[column])\n",
        "    train_data = pd.concat([train_data, feature], axis=1)\n",
        "  \n",
        "  return train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWE_i1JtIpbS"
      },
      "source": [
        "###Create Final Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rAF18tmE4n7"
      },
      "source": [
        "data_final = one_hot_final().copy()\n",
        "print(data_final.shape)\n",
        "data_final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnXYRZO7GU_h"
      },
      "source": [
        "'Ones' in data_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv8RHR44DORk"
      },
      "source": [
        "###Nonlinear Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7BY9pctIktY"
      },
      "source": [
        "look as an array of powers to see which works best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_J_bj9rg7ZD"
      },
      "source": [
        "data_final['SalePrice'].index[data_final['SalePrice'].apply(np.isnan)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDQ_QU4sLs5A"
      },
      "source": [
        "print(type(data_final))\n",
        "print(data_final.isna().sum().sum())\n",
        "print(type(data_final['SalePrice']))\n",
        "print(data_final['SalePrice'].isna().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BWWKpoCDdSl"
      },
      "source": [
        "power_array = 1/np.arange(1,10,1)\n",
        "train = data_final.drop(['SalePrice'], axis=1)\n",
        "outcomes = data_final['SalePrice']\n",
        "mean_errors = []\n",
        "\n",
        "for power in power_array:\n",
        "  validation_error = []\n",
        "  for idx in range(500):\n",
        "    x_train, x_test, y_train, y_test = model_selection.train_test_split(train, outcomes, test_size=0.2)\n",
        "    y_train_raised_to_power = y_train.pow(power)\n",
        "    model = sm.OLS(y_train_raised_to_power, x_train).fit()\n",
        "    predict = model.predict(x_test)\n",
        "    final_predict = predict.pow(1/power)\n",
        "    validation_error.append(np.sqrt(np.mean(np.square((y_test - final_predict)/y_test)))*100)\n",
        "\n",
        "  mean_errors.append(np.mean(validation_error))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmeeis36Gvg9"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(power_array, mean_errors)\n",
        "plt.xlabel('Power')\n",
        "plt.ylabel('Root Mean Squared Precentage Error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSi5pM9lv6_W"
      },
      "source": [
        "print(list(zip(mean_errors,power_array)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyc8WPVcxAXC"
      },
      "source": [
        "From the Graph and the list above we can see that using a power of 1/3 gives us the best outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtGF6RliiXgf"
      },
      "source": [
        "##Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXkmBX5rGXns"
      },
      "source": [
        "###Split Training Data Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPdCtcsnF9_P"
      },
      "source": [
        "Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HtzYrPpViBV"
      },
      "source": [
        "data_final_features = data_final.drop(['SalePrice'], axis=1).copy()\n",
        "data_outcome = data_final['SalePrice'].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vByrcTOcx3jv"
      },
      "source": [
        "Apply power to outcomes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTo_jpF_yKJb"
      },
      "source": [
        " data_final_outcome = data_outcome.pow(1/3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCBr_04eCU95"
      },
      "source": [
        "###Improt Blind Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm-4uDU8EjLf"
      },
      "source": [
        "blind_data_path = '/content/drive/My Drive/Exercises - Benjamin/Project 2/Copy of Housing Data Blind Test.csv'\n",
        "blind_data = pd.read_csv(blind_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8XlWS6HGrmR"
      },
      "source": [
        "###Inspect Blind Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bgSmbfyFHyp"
      },
      "source": [
        "blind_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBCIz2_1TmJr"
      },
      "source": [
        "blind_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_ryfOO9UAQf"
      },
      "source": [
        "No Nan values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWuu0NlaTlqL"
      },
      "source": [
        "blind_data.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcHQlPz7UD4R"
      },
      "source": [
        "###Seperate Numerical and Object Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_pdGAV04fio"
      },
      "source": [
        "blind_data_numerical = blind_data.select_dtypes(exclude='object').copy()\n",
        "blind_data_objects = blind_data.select_dtypes(include='object').copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw28SnN95l4E"
      },
      "source": [
        "###One Hot Encode Object Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENJlmZUc664N"
      },
      "source": [
        "blind_data_onehot = pd.get_dummies(blind_data_objects)\n",
        "blind_data_onehot.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfCVzvMN5sV0"
      },
      "source": [
        "###Scale Numerical Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGtUNq-45wxX"
      },
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "scaled_data = scaler.fit_transform(blind_data_numerical)\n",
        "blind_data_scaled = pd.DataFrame(scaled_data, columns= blind_data_numerical.columns)\n",
        "blind_data_scaled.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW9RVuUu-DLX"
      },
      "source": [
        "Add a ones column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bLCtnje-J1_"
      },
      "source": [
        "blind_data_scaled['Ones'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_PBuHtp8FeL"
      },
      "source": [
        "###Join One Hot and Scaled Numerical Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgVrfFVE8Q9I"
      },
      "source": [
        "blind_data_joined = pd.concat([blind_data_scaled, blind_data_onehot], axis=1)\n",
        "blind_data_joined.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xaXEWJokemC"
      },
      "source": [
        "create test data with only columns also in the traingin data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERpcvwSk85HM"
      },
      "source": [
        "column_intersection = blind_data_joined.columns.intersection(data_final_features.columns)\n",
        "blind_data_final = blind_data_joined.loc[:, column_intersection].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cavU2wLa_BAE"
      },
      "source": [
        "###Inspect Final Blind Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_F9MQuM_FXY"
      },
      "source": [
        "print(blind_data_final.shape)\n",
        "blind_data_final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBmge3Vn7P46"
      },
      "source": [
        "###Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHi17DGbkJTi"
      },
      "source": [
        "create training features with only colums also in the blind test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MH019z_kHpD"
      },
      "source": [
        "training_data_final = data_final_features.loc[:, blind_data_final.columns] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2U7jrLlGd-p"
      },
      "source": [
        "final_model = sm.OLS(data_final_outcome, training_data_final).fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-fKYeNNf3Ms"
      },
      "source": [
        "###Predict Sale Price Using Blind Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVISW7e5gACk"
      },
      "source": [
        "test_prediction_blind_data = final_model.predict(blind_data_final).pow(3)\n",
        "print(test_prediction_blind_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTZmBWolXw_M"
      },
      "source": [
        "###Export Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPGZhE3SXxfO"
      },
      "source": [
        "test_prediction_blind_data.to_csv('/content/drive/My Drive/Exercises - Benjamin/Project 2/Blind Test Predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrrB-PoJifNJ"
      },
      "source": [
        "##Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgAd2A5ilTXC"
      },
      "source": [
        "### Nonlinear Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAKZ6fIv_2_0"
      },
      "source": [
        "####Power Used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6jY4grNtOTe"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(power_array, mean_errors)\n",
        "plt.xlabel('Power')\n",
        "plt.ylabel('Root Mean Squared Precentage Error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbNciRFt_9Bw"
      },
      "source": [
        "####Without Nonlinear Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj6l-x4FyUBm"
      },
      "source": [
        "model = sm.OLS(data_outcome, training_data_final).fit() \n",
        "prediction = model.predict(training_data_final)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(data_outcome,prediction)\n",
        "plt.plot([0, max(prediction)],[0, max(prediction)], c='red');\n",
        "\n",
        "plt.xlabel('Real Sales Price',fontsize=16);\n",
        "plt.ylabel('Predictions',fontsize=16);\n",
        "\n",
        "plt.axis('equal');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWjuIj6kAeoq"
      },
      "source": [
        "####With Nonlinear Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npzP8R-4t03q"
      },
      "source": [
        "model = sm.OLS(data_final_outcome, training_data_final).fit() \n",
        "prediction = model.predict(training_data_final)\n",
        "\n",
        "prediction = prediction.pow(3)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(data_outcome,prediction)\n",
        "plt.plot([0, max(prediction)],[0, max(prediction)], c='red')\n",
        "\n",
        "plt.xlabel('Real Sales Price',fontsize=16)\n",
        "plt.ylabel('Predictions',fontsize=16)\n",
        "\n",
        "plt.axis('equal');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Y4TX1KXO-u"
      },
      "source": [
        "###One Hot Features Added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqwJaRbeB1g8"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(range(45), one_hot_error)\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Root Mean Squared Precentage Error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfuVDIcRXcqv"
      },
      "source": [
        "###Numeric Features Added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wGgWqQJXacP"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(numeric_features_error['rms_error'])\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Root Mean Squared Percentage Error')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}